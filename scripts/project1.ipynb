{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#just for the notebook\n",
    "%run implementations\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138.47 ,  51.655,  97.827, ...,   1.24 ,  -2.475, 113.497],\n",
       "       [160.937,  68.768, 103.235, ...,     nan,     nan,  46.226],\n",
       "       [    nan, 162.172, 125.953, ...,     nan,     nan,  44.251],\n",
       "       ...,\n",
       "       [105.457,  60.526,  75.839, ...,     nan,     nan,  41.992],\n",
       "       [ 94.951,  19.362,  68.812, ...,     nan,     nan,   0.   ],\n",
       "       [    nan,  72.756,  70.831, ...,     nan,     nan,   0.   ]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace -999 with nan\n",
    "tX = replace_999_with_nan(tX)\n",
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substract mean and divide by std\n",
    "tX = normalize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.where(np.isnan(tX))\n",
    "\n",
    "tX[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.51508626e-02  1.02028164e-16  9.75131087e-18  9.16200449e-17\n",
      " -1.20898347e-01 -2.60406414e-01  1.14403083e-01 -7.39790673e-16\n",
      " -4.45660397e-16 -9.45576950e-17  3.87708976e-16  5.77852433e-16\n",
      " -7.63778263e-03  4.18840296e-16  2.33848496e-17  4.32400782e-17\n",
      " -5.84950755e-16 -3.10063086e-18 -8.78408457e-18 -3.76882969e-16\n",
      " -2.60067523e-17 -4.27278657e-16  9.79176000e-01 -1.26895413e-01\n",
      "  7.33351673e-04 -4.54163006e-03 -2.16983065e-01  6.44682656e-04\n",
      " -1.63188290e-04  3.71608522e-16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain mean of columns as you need, nanmean is just convenient.\n",
    "col_mean = np.nanmean(tX, axis=0)\n",
    "print(col_mean)\n",
    "\n",
    "\n",
    "#Find indicies that you need to replace\n",
    "inds = np.where(np.isnan(tX))\n",
    "\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "tX[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "inds = np.where(np.isnan(tX))\n",
    "inds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = split_data(tX, y, 0.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y_test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append y values as column to later divide y into buckets corresponding with x values\n",
    "train = np.column_stack((x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training x into buckets\n",
    "buckets = get_buckets(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "initial_weights = np.ones(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import log_reg\n",
    "# Least squares\n",
    "#w , loss = least_squares(y_train,x_train)\n",
    "\n",
    "# Least squares GD\n",
    "#w , loss = least_squares_GD(y_train,x_train,initial_weights,200,0.01)\n",
    "\n",
    "# Ridge regression\n",
    "w,loss = ridge_regression(y_train,x_train,0.001)\n",
    "\n",
    "# Logistic regression\n",
    "#w,loss = log_reg(y_train,x_train,initial_weights,300,1)\n",
    "\n",
    "# reg logistic regression\n",
    "#w,loss = reg_logistic_regression(y_train,x_train,0.001,initial_weights,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.80847646e-02, -2.49250570e-01, -2.59649680e-01,  3.39065165e-02,\n",
       "        3.21117036e-02,  2.50253917e-01,  3.61480342e-02,  2.74732259e-01,\n",
       "       -3.99510065e-02, -1.21071893e+00, -1.86328635e-01,  1.25672144e-01,\n",
       "        1.24077483e-01,  4.13290101e-01,  2.15460260e-04, -1.21488629e-03,\n",
       "        5.10619196e-01, -6.39629903e-04,  2.86357982e-03,  9.30359899e-02,\n",
       "        3.49431665e-04, -4.27359314e-02, -3.41691519e-01, -4.31453221e-01,\n",
       "       -4.67763366e-04,  4.47027542e-04, -2.56593496e-01,  3.43294573e-03,\n",
       "       -3.82869377e-03,  1.59079095e+00])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = w\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sub.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w\n",
    "y_pred = predict_labels(weights,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.80847646e-02, -2.49250570e-01, -2.59649680e-01,  3.39065165e-02,\n",
       "        3.21117036e-02,  2.50253917e-01,  3.61480342e-02,  2.74732259e-01,\n",
       "       -3.99510065e-02, -1.21071893e+00, -1.86328635e-01,  1.25672144e-01,\n",
       "        1.24077483e-01,  4.13290101e-01,  2.15460260e-04, -1.21488629e-03,\n",
       "        5.10619196e-01, -6.39629903e-04,  2.86357982e-03,  9.30359899e-02,\n",
       "        3.49431665e-04, -4.27359314e-02, -3.41691519e-01, -4.31453221e-01,\n",
       "       -4.67763366e-04,  4.47027542e-04, -2.56593496e-01,  3.43294573e-03,\n",
       "       -3.82869377e-03,  1.59079095e+00])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  74.51\n",
      "precision :  0.6652420602755876\n",
      "recall :  0.5239698200812536\n",
      "F1 score :  0.5862147332878802\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy \n",
    "true_positive = 0\n",
    "false_positive = 0 \n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "\n",
    "testing_length = y_test.shape[0]\n",
    "for i in range(testing_length):      \n",
    "    if (y_test[i] == y_pred[i]) and (y_pred[i]==1):        \n",
    "        true_positive += 1\n",
    "    if (y_test[i] == y_pred[i]) and (y_pred[i]==-1):\n",
    "        true_negative +=1        \n",
    "    if (y_test[i] != y_pred[i]) and (y_pred[i]==-1):    \n",
    "        false_negative += 1\n",
    "    if (y_test[i] != y_pred[i]) and (y_pred[i]==1):\n",
    "        false_positive +=1\n",
    "        \n",
    "        \n",
    "precision = true_positive/float(true_positive+false_positive)\n",
    "recall =true_positive/float(true_positive + false_negative)\n",
    "F=2 *(precision*recall)/float(precision+recall)        \n",
    "    \n",
    "\n",
    "print('Train accuracy: ',  ((true_positive+true_negative)/float(testing_length))*100.0)\n",
    "print(\"precision : \", precision)\n",
    "print(\"recall : \",recall)\n",
    "print(\"F1 score : \",F)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
